{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/eBRPvWB.png)\n",
    "\n",
    "# Practical PyTorch: Generating Shakespeare with a Character-Level RNN\n",
    "\n",
    "[In the RNN classification tutorial](https://github.com/spro/practical-pytorch/blob/master/char-rnn-classification/char-rnn-classification.ipynb) we used a RNN to classify text one character at a time. This time we'll generate text one character at a time.\n",
    "\n",
    "```\n",
    "> python generate.py -n 500\n",
    "\n",
    "PAOLTREDN:\n",
    "Let, yil exter shis owrach we so sain, fleas,\n",
    "Be wast the shall deas, puty sonse my sheete.\n",
    "\n",
    "BAUFIO:\n",
    "Sirh carrow out with the knonuot my comest sifard queences\n",
    "O all a man unterd.\n",
    "\n",
    "PROMENSJO:\n",
    "Ay, I to Heron, I sack, againous; bepear, Butch,\n",
    "An as shalp will of that seal think.\n",
    "\n",
    "NUKINUS:\n",
    "And house it to thee word off hee:\n",
    "And thou charrota the son hange of that shall denthand\n",
    "For the say hor you are of I folles muth me?\n",
    "```\n",
    "\n",
    "This one might make you question the series title &mdash; \"is that really practical?\" However, these sorts of generative models form the basis of machine translation, image captioning, question answering and more. See the [Sequence to Sequence Translation tutorial](https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation.ipynb) for more on that topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommended Reading\n",
    "\n",
    "I assume you have at least installed PyTorch, know Python, and understand Tensors:\n",
    "\n",
    "* http://pytorch.org/ For installation instructions\n",
    "* [Deep Learning with PyTorch: A 60-minute Blitz](https://github.com/pytorch/tutorials/blob/master/Deep%20Learning%20with%20PyTorch.ipynb) to get started with PyTorch in general\n",
    "* [jcjohnson's PyTorch examples](https://github.com/jcjohnson/pytorch-examples) for an in depth overview\n",
    "* [Introduction to PyTorch for former Torchies](https://github.com/pytorch/tutorials/blob/master/Introduction%20to%20PyTorch%20for%20former%20Torchies.ipynb) if you are former Lua Torch user\n",
    "\n",
    "It would also be useful to know about RNNs and how they work:\n",
    "\n",
    "* [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) shows a bunch of real life examples\n",
    "* [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) is about LSTMs specifically but also informative about RNNs in general\n",
    "\n",
    "Also see these related tutorials from the series:\n",
    "\n",
    "* [Classifying Names with a Character-Level RNN](https://github.com/spro/practical-pytorch/blob/master/char-rnn-classification/char-rnn-classification.ipynb) uses an RNN for classification\n",
    "* [Generating Names with a Conditional Character-Level RNN](https://github.com/spro/practical-pytorch/blob/master/conditional-char-rnn-generation/conditional-char-rnn-generation.ipynb) builds on this model to add a category as input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data\n",
    "\n",
    "Split into trainable chunks of 110 characters each. The first 10 characters will always be used as context, and the model will try to predict the next 100. There is no special consideration for where a chunk starts (it could be smart to e.g. always start on a newline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "# Turn Unicode to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_characters\n",
    "    )\n",
    "\n",
    "file = unicodeToAscii(open('../data/shakespeare.txt').read())\n",
    "file_len = len(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e cap your worship did bespeak.\n",
      "\n",
      "PETRUCHIO:\n",
      "Why, this was moulded on a porringer;\n",
      "A velvet dish: fie, fie! 'tis lewd and filthy:\n",
      "Why, 'tis a cockle or a walnut-shell,\n",
      "A knack, a toy, a trick, a baby's \n"
     ]
    }
   ],
   "source": [
    "chunk_len = 200\n",
    "\n",
    "def random_chunk():\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "print(random_chunk())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Turn string into set of of one-hot vectors\n",
    "def make_input(string):\n",
    "    tensor = torch.zeros(len(string), n_characters)\n",
    "    for c in range(len(string)):\n",
    "        i = all_characters.index(string[c])\n",
    "        tensor[c][i] = 1\n",
    "    return Variable(tensor)\n",
    "\n",
    "# Turn string into list of longs\n",
    "def make_target(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        i = all_characters.index(string[c])\n",
    "        tensor[c] = i\n",
    "    return Variable(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_training_set():    \n",
    "    chunk = random_chunk()\n",
    "    inp = make_input(chunk[:-1])\n",
    "    target = make_target(chunk[1:])\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Model\n",
    "\n",
    "This is a simple RNN with layers that encode to a smaller GRU, then decode back out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder = nn.Linear(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        input = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
    "    hidden = decoder.init_hidden()\n",
    "    prime_input = make_input(prime_str)\n",
    "    predicted = prime_str\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = decoder(prime_input[p], hidden)\n",
    "        \n",
    "    inp = prime_input[-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = decoder(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = make_input(predicted_char)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def time_since(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 46s (100 5%) 3.3622\n",
      "--> Wh ate aW pnrWsgmi uihto ti tl thov y ou\n",
      " oe to  ah n ttathi c  trnmThe\n",
      " e tlae e  M tttltpo  d  s n e \n",
      "<--\n",
      "\n",
      "1m 32s (200 10%) 2.5020\n",
      "--> Wh erte es il ke a fay ey hounk, rane uoir aitd yit hhor fet iou rose ton teh leh heh irpe hof thon wo \n",
      "<--\n",
      "\n",
      "2m 17s (300 15%) 2.5799\n",
      "--> What tars serob'cd os som asdce,\n",
      "\n",
      "RIY IRENRTDNY:\n",
      "Tol; hacte ane coms co ale if he,\n",
      "\n",
      "ICEOTRKEN:\n",
      "\n",
      "IN:\n",
      "\n",
      "K \n",
      "<--\n",
      "\n",
      "3m 3s (400 20%) 2.3707\n",
      "--> Whab fhushs sone sreo he angake\n",
      "Toor ansem.\n",
      "Hef bitlen sere case bou res shangalt ho af theve hive,\n",
      "Th \n",
      "<--\n",
      "\n",
      "3m 49s (500 25%) 2.4492\n",
      "--> Whod antE ontt teld ontt farlite odid pusgleef\n",
      "Horde the gorlst I har,\n",
      "Yor yamo taols!\n",
      " hame badren th \n",
      "<--\n",
      "\n",
      "4m 35s (600 30%) 2.3445\n",
      "--> Whrit there yy\n",
      "Were pratirl ancing the shat bere in liou-Lome\n",
      "\n",
      "OCECLICA:\n",
      "A nath you\n",
      "Whace karddire anc \n",
      "<--\n",
      "\n",
      "5m 22s (700 35%) 2.2857\n",
      "--> What so me lot moun thear woos seer to fond, wonle sored!\n",
      "\n",
      "ITAS:\n",
      "And heas's here nicpome bash, tho mad \n",
      "<--\n",
      "\n",
      "6m 9s (800 40%) 2.1228\n",
      "--> Whill to sull in wor bere\n",
      "And and we aPen thes the ol howy kelh ale only to the to ince\n",
      "Ner! be the's  \n",
      "<--\n",
      "\n",
      "6m 57s (900 45%) 2.1539\n",
      "--> Whowgiad sade sen suilh,\n",
      "The me a bour\n",
      "Mou breamtt youst weendelh end ine the mithone to deant\n",
      "Row Dan \n",
      "<--\n",
      "\n",
      "7m 44s (1000 50%) 2.1280\n",
      "--> Whe she us; and shing thou the tung I mold.\n",
      "\n",
      "ISALARINEUS:\n",
      "So mave belld end you thee daed to his. I sa \n",
      "<--\n",
      "\n",
      "8m 30s (1100 55%) 2.1966\n",
      "--> Whind,\n",
      "And he whor whe bame bats, and he yo the the may.\n",
      "\n",
      "GUCICET:\n",
      "Suct so, my lhord dlemeras,\n",
      "As ha;  \n",
      "<--\n",
      "\n",
      "9m 17s (1200 60%) 2.0717\n",
      "--> Wherter and deighink, wherise Weret a mell agk we fo\n",
      "Wis she thied that as ungatale it dome my greaghe \n",
      "<--\n",
      "\n",
      "10m 4s (1300 65%) 2.0765\n",
      "--> Wheart what be noegt deant.\n",
      "\n",
      "TACKUNTIO:\n",
      "So mince suint with te getert.\n",
      "\n",
      "BRAUCEO:\n",
      "Bouns of that shath a \n",
      "<--\n",
      "\n",
      "10m 50s (1400 70%) 2.0779\n",
      "--> Whers tlron lull coy are of Morden,\n",
      "And Morginsint onl dicen, unimes Bor cons now world from why:\n",
      "Mesc \n",
      "<--\n",
      "\n",
      "11m 35s (1500 75%) 2.0451\n",
      "--> Wheress in bering.\n",
      "\n",
      "AmLOUS:\n",
      "How in haze lighy, wheresgelar the fation, beink so,\n",
      "Histre, Lrard now, in \n",
      "<--\n",
      "\n",
      "12m 22s (1600 80%) 2.0706\n",
      "--> Wherd's incend boring this inte detsed\n",
      "Thou mother's a torsed with mised from Lorrd hear be and I meen \n",
      "<--\n",
      "\n",
      "13m 8s (1700 85%) 2.1481\n",
      "--> What and to porty,\n",
      "Undobe stered and the sor or thing the lands\n",
      "The peppoty, for for read me wut his w \n",
      "<--\n",
      "\n",
      "13m 55s (1800 90%) 1.9449\n",
      "--> Whake, the warg wory your\n",
      "That trick ismacle but the wo the hommps,\n",
      "I sjards yast and wath seop will a \n",
      "<--\n",
      "\n",
      "14m 40s (1900 95%) 1.9322\n",
      "--> When here forrond, and wime.\n",
      "\n",
      "LUKE:\n",
      "Mesto the king beont, vencestent the loogter\n",
      "The it stise for bell \n",
      "<--\n",
      "\n",
      "15m 26s (2000 100%) 2.0025\n",
      "--> When it he hest boncent\n",
      "wand ri, Goven for woufpeapnep,\n",
      "And mow you will, a cood theys on he mang,\n",
      "\n",
      "AR \n",
      "<--\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 2000\n",
    "print_every = 100\n",
    "plot_every = 50\n",
    "hidden_size = 50\n",
    "n_layers = 2\n",
    "lr = 0.005\n",
    "\n",
    "decoder = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "def train(inp, target):\n",
    "    hidden = decoder.init_hidden()\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    # Read predictions\n",
    "    for c in range(chunk_len):\n",
    "        output, hidden = decoder(inp[c], hidden)\n",
    "        loss += criterion(output.view(-1), target[c])\n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / chunk_len\n",
    "        \n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(*random_training_set())       \n",
    "    loss_avg += loss\n",
    "    \n",
    "    if epoch % print_every == 0:\n",
    "        print('%s (%d %d%%) %.4f' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
    "        print('-->', evaluate('Wh', 100), '\\n<--\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Network\n",
    "\n",
    "Plotting the historical loss from all_losses shows the network learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x111189898>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAFdCAYAAACJlf6EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106c4b630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thandyen he theser for the more\n",
      "I the kins vering the be ar.\n",
      "\n",
      "CELUETEL:\n",
      "Nor this dud see the will so fare of age uigher\n",
      "Thou Sather the not and so the hove his como.\n",
      "\n",
      "CEMEMENMOUS:\n",
      "There, the wand lenleing!d were bind,\n",
      "What and the blase ceane gcand,\n",
      "In she tame will this wad, what a date.\n",
      "\n",
      "GMLIOLAS:\n",
      "In have stremand hant of to you to!\n",
      "\n",
      "LORWISO:\n",
      "The goovers sucmt think blaes wear lear\n",
      "To the waint, than to so thy is my ade entaneds.\n",
      "\n",
      "CAMILENTEN:\n",
      "Caystol, in as you be you of but, dive failite the,\n",
      "I\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('Th', 500, temperature=0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
